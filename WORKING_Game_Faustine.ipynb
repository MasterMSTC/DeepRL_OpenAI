{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WORKING_Game_Faustine.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"BMM6VYZ05ezB","colab_type":"text"},"cell_type":"markdown","source":["# Matches game:\n","\n","## 12 matches\n","\n","- ## Each player can take 1, 2 or 3 matches\n","\n","- ## <font color = red> Donâ€™t be the last to take a match</font>\n","  \n","  \n","## Example from: <font color=green>Faustine Gusto </font>\n","\n"]},{"metadata":{"id":"QYSYuCGEaX9j","colab_type":"code","colab":{}},"cell_type":"code","source":["from random import randint\n","import random\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vRr4YU4c6Rq2","colab_type":"text"},"cell_type":"markdown","source":["---\n","# First we need an \"environment\" (game) simulator: \n","\n","- ### Input: <font color=blue>action</font>\n","- ### Outputs:  <font color=orange>next state (number of matches)</font> & <font color=orange>REWARD</font> ( -1 no more matches left)"]},{"metadata":{"id":"cNy8rsGiaa9q","colab_type":"code","colab":{}},"cell_type":"code","source":["class StickGame(object):\n","    \"\"\"\n","        StickGame.\n","    \"\"\"\n","\n","    def __init__(self, nb):\n","        # @nb Number of stick to play with\n","        super(StickGame, self).__init__()\n","        self.original_nb = nb\n","        self.nb = nb\n","\n","    def is_finished(self):\n","        # Check if the game is over @return Boolean\n","        if self.nb <= 0:\n","            return True\n","        return False\n","\n","    def reset(self):\n","        # Reset the state of the game\n","        self.nb = self.original_nb\n","        return self.nb\n","\n","    def display(self):\n","        # Display the state of the game\n","        print (\"| \" * self.nb)\n","\n","    def step(self, action):\n","        # @action either 1, 2 or 3. Take an action into the environement\n","        self.nb -= action\n","        if self.nb <= 0:\n","            return None, -1\n","        else:\n","            return self.nb, 0\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"uTVx9kOB7n3l"},"cell_type":"markdown","source":["---\n","# We also need an \"Agent\" (StickPlayer class): \n","\n","- ### Input: <font color=blue>state</font>\n","- ### Outputs:  <font color=orange>next action</font>\n","\n","---\n","---\n","\n","## Also in StickPlayer class:\n","\n","- ### game *history* is stored\n","\n","- ### and there is a <font color=red>TRAINING</font> function for the <font color=magenta> Value Function V[ ]</font> which is a peculiar funtion\n","\n","### <font color=FF103>TO DO: define this training function </font> \n","    First you will need to understand first how is V used in  *greedy_step* function\n","\n"]},{"metadata":{"id":"a9tFFqTYaOsD","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","class StickPlayer(object):\n","    \"\"\"\n","        Stick Player\n","    \"\"\"\n","\n","    def __init__(self, is_human, size, trainable=True):\n","        # @nb Number of stick to play with\n","        super(StickPlayer, self).__init__()\n","        self.is_human = is_human\n","        self.history = []\n","        self.V = {}\n","        for s in range(1, size+1):\n","            self.V[s] = 0.\n","        self.win_nb = 0.\n","        self.lose_nb = 0.\n","        self.rewards = []\n","        self.eps = 0.99\n","        self.trainable = trainable\n","\n","    def reset_stat(self):\n","        # Reset stat\n","        self.win_nb = 0\n","        self.lose_nb = 0\n","        self.rewards = []\n","\n","    def greedy_step(self, state):\n","        # Greedy step\n","        actions = [1, 2, 3]\n","        vmin = None\n","        vi = None\n","        for i in range(0, 3):\n","            a = actions[i]\n","            if state - a > 0 and (vmin is None or vmin > self.V[state - a]):\n","                vmin = self.V[state - a]\n","                vi = i\n","        return actions[vi if vi is not None else 1]\n","\n","    def play(self, state):\n","        # PLay given the @state (int)\n","        if self.is_human is False:\n","            # Take random action\n","            if random.uniform(0, 1) < self.eps:\n","                action = randint(1, 3)\n","            else: # Or greedy action\n","                action = self.greedy_step(state)\n","        else:\n","            action = int(input(\"$>\"))\n","        return action\n","\n","    def add_transition(self, n_tuple):\n","        # Add one transition to the history: tuple (s, a , r, s')\n","        self.history.append(n_tuple)\n","        s, a, r, sp = n_tuple\n","        self.rewards.append(r)\n","\n","    def train(self):\n","        if not self.trainable or self.is_human is True:\n","            return\n","\n","        # Update the value function if this player is not human\n","        for transition in reversed(self.history):\n","            s, a, r, sp = transition\n","            if r == 0:\n","                self.V[s] = self.V[s]\n","            else:\n","                self.V[s] = self.V[s]\n","\n","        self.history = []\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"lhV2fjch-ekj"},"cell_type":"markdown","source":["---\n","# This is the function to play the game!\n","\n","## Note that:\n","\n","- ### There are 2 Players!\n","- ### Who starts playing is randomized\n","\n","### Players'  *history* is stored: <font color=blue>player.history</font>\n","### Players' results are also stored: <font color=blue>player.win_nb</font> & <font color=blue>player.lose_nb</font>\n","\n","## If players' train flag is 'True' value function for non-human players are trained using history\n","\n","---\n","---\n","\n"]},{"metadata":{"id":"NavvIb1ecJ05","colab_type":"code","colab":{}},"cell_type":"code","source":["def play(game, p1, p2, train=True):\n","    state = game.reset()\n","    players = [p1, p2]\n","    random.shuffle(players)\n","    p = 0\n","    while game.is_finished() is False:\n","\n","        if players[p%2].is_human:\n","            game.display()\n","\n","        action = players[p%2].play(state)\n","        n_state, reward = game.step(action)\n","\n","        #  Game is over. Ass stat\n","        if (reward != 0):\n","            # Update stat of the current player\n","            players[p%2].lose_nb += 1. if reward == -1 else 0\n","            players[p%2].win_nb += 1. if reward == 1 else 0\n","            # Update stat of the other player\n","            players[(p+1)%2].lose_nb += 1. if reward == 1 else 0\n","            players[(p+1)%2].win_nb += 1. if reward == -1 else 0\n","\n","        # Add the reversed reward and the new state to the other player\n","        if p != 0:\n","            s, a, r, sp = players[(p+1)%2].history[-1]\n","            players[(p+1)%2].history[-1] = (s, a, reward * -1, n_state)\n","\n","        players[p%2].add_transition((state, action, reward, None))\n","\n","        state = n_state\n","        p += 1\n","\n","    \n","    if train:\n","        p1.train()\n","        p2.train()\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"xRQlDT7lAg6Z"},"cell_type":"markdown","source":["---\n","# Now you can try playing against a random Agent (player)\n","\n","---\n","---\n","\n"]},{"metadata":{"id":"2kBiDcUJ1sam","colab_type":"code","colab":{}},"cell_type":"code","source":["game = StickGame(12)\n","\n","\n","# Human player and random player\n","human = StickPlayer(is_human=True, size=12, trainable=False)\n","random_player = StickPlayer(is_human=False, size=12, trainable=False)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nw1um8MR4h1-","colab_type":"code","colab":{}},"cell_type":"code","source":["play(game, human, random_player)\n","\n","print('Human wins: ', human.win_nb, ' Random player wins: ', random_player.win_nb)\n","\n","print('Player p1 history \\n ',human.history)\n","print('Player p2 history \\n ',random_player.history)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"F0NL3byjBdE5"},"cell_type":"markdown","source":["---\n","# ... you can try two random Agents....\n","\n","---\n","---\n","\n"]},{"metadata":{"id":"N_guQNWrzt2r","colab_type":"code","colab":{}},"cell_type":"code","source":["game = StickGame(12)\n","\n","# Random Players to train\n","p1_rand = StickPlayer(is_human=False, size=12, trainable=False)\n","p2_rand = StickPlayer(is_human=False, size=12, trainable=False)\n","\n","print(p1_rand.eps)\n","print(p2_rand.eps)\n","\n","p1_rand.reset_stat()\n","p2_rand.reset_stat()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AetzCN-l0iJ_","colab_type":"code","colab":{}},"cell_type":"code","source":["play(game, p1_rand, p2_rand)\n","\n","print('p1 rand wins : ', p1_rand.win_nb, 'p2 rand wins: ', p2_rand.win_nb)\n","\n","print('Player p1 rand history \\n ',p1_rand.history)\n","print('Player p2 rand history \\n ',p2_rand.history)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"QUUZl2iRDo3z"},"cell_type":"markdown","source":["---\n","# Now we <font color=red>TRAIN</font> two Agents....\n","\n","---\n","---\n","\n"]},{"metadata":{"id":"_ns5gEnRaOsd","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","game = StickGame(12)\n","\n","# PLayers to train\n","p1 = StickPlayer(is_human=False, size=12, trainable=True)\n","p2 = StickPlayer(is_human=False, size=12, trainable=True)\n","\n","\n","# Train the agent\n","for i in range(0, 10000):\n","    if i % 10 == 0:\n","      p1.eps = max(p1.eps*0.996, 0.05)\n","      p2.eps = max(p2.eps*0.996, 0.05)\n","    play(game, p1, p2)\n","\n","p1.reset_stat()\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W7qfOmlTdftz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Display the value function\n","for key in p1.V:\n","     print(key, p1.V[key])\n","     print(\"------------------------------\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oCLgbwDaEAjI","colab_type":"text"},"cell_type":"markdown","source":["## ...try against a random agent"]},{"metadata":{"id":"7qAU0sJmdAQL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Play agains a random player\n","for _ in range(0, 1000):\n","     play(game, p1, random_player, train=False)\n","print(\"p1 win rate\", p1.win_nb/(p1.win_nb + p1.lose_nb))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"axp5zRYCDGI1"},"cell_type":"markdown","source":["---\n","# Now you can try playing against a <font color=red>trained</fon> Agent !!!\n","\n","---\n","---\n","\n"]},{"metadata":{"id":"iSeeVyqWC05p","colab_type":"code","colab":{}},"cell_type":"code","source":["play(game, p1, human, train=False)\n","\n","print('p1 wins : ', p1.win_nb, 'human wins: ', human.win_nb)\n","\n","print('Player p1 rand history \\n ',p1.history)\n","print('Player human history \\n ',human.history)\n"],"execution_count":0,"outputs":[]}]}